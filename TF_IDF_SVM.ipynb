{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24e0244-33cf-4b8f-9960-1e32533f7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab8a61e-1b48-42c2-8ea0-2fd8dfeb6495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected TEXT column : 0                      \"like this if you are a tribe fan\"\n",
      "1                   \"you're idiot.......................\"\n",
      "2       \"I am a woman Babs, and the only \"war on women...\n",
      "3       \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...\n",
      "4       \"haha green me red you now loser whos winning ...\n",
      "                              ...                        \n",
      "2230    \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...\n",
      "2231    \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...\n",
      "2232    \"sweetie pie is looking very much like her cou...\n",
      "2233    \"ball4real where are you with your miami g-ayn...\n",
      "2234    \"Man....if you are a 3 point shooter, you must...\n",
      "Name: Comment, Length: 2235, dtype: object\n",
      "Detected LABEL column: 0       0\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2230    0\n",
      "2231    1\n",
      "2232    0\n",
      "2233    1\n",
      "2234    0\n",
      "Name: Insult, Length: 2235, dtype: int64\n",
      "DataFrame created:\n",
      "\n",
      "\n",
      "===============================\n",
      "Logistic Regression\n",
      "===============================\n",
      "Accuracy: 0.7024608501118568\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       232\n",
      "           1       0.70      0.67      0.68       215\n",
      "\n",
      "    accuracy                           0.70       447\n",
      "   macro avg       0.70      0.70      0.70       447\n",
      "weighted avg       0.70      0.70      0.70       447\n",
      "\n",
      "Confusion Matrix:\n",
      "[[170  62]\n",
      " [ 71 144]]\n",
      "ROC-AUC: 0.791228949478749\n",
      "\n",
      "===============================\n",
      "Linear SVM\n",
      "===============================\n",
      "Accuracy: 0.7203579418344519\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73       232\n",
      "           1       0.71      0.72      0.71       215\n",
      "\n",
      "    accuracy                           0.72       447\n",
      "   macro avg       0.72      0.72      0.72       447\n",
      "weighted avg       0.72      0.72      0.72       447\n",
      "\n",
      "Confusion Matrix:\n",
      "[[168  64]\n",
      " [ 61 154]]\n",
      "\n",
      "===============================\n",
      "Naive Bayes\n",
      "===============================\n",
      "Accuracy: 0.7136465324384788\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       232\n",
      "           1       0.72      0.66      0.69       215\n",
      "\n",
      "    accuracy                           0.71       447\n",
      "   macro avg       0.71      0.71      0.71       447\n",
      "weighted avg       0.71      0.71      0.71       447\n",
      "\n",
      "Confusion Matrix:\n",
      "[[178  54]\n",
      " [ 74 141]]\n",
      "ROC-AUC: 0.8075080192461909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# NLTK setup\n",
    "# ===============================\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    return wordnet.NOUN\n",
    "\n",
    "# ===============================\n",
    "# Load Dataset\n",
    "# ===============================\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\Jannatul Mawya\\OneDrive\\Pictures\\Cyberbullying Thesis\\impermium_verification_labels.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "#text_col =  None\n",
    "#label_col = None\n",
    "text_col =  df['Comment']\n",
    "label_col = df['Insult']\n",
    "\n",
    "'''\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object and text_col is None:\n",
    "      text_col = col\n",
    "    elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "        label_col = col\n",
    "'''\n",
    "if text_col is None or label_col is None:\n",
    "    raise ValueError(\"Could not detect text/label columns\")\n",
    "\n",
    "print(f\"Detected TEXT column : {text_col}\")\n",
    "print(f\"Detected LABEL column: {label_col}\")\n",
    "\n",
    "\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df['Insult'] = df['Insult'].astype(int)\n",
    "print(\"DataFrame created:\\n\")\n",
    "# ===============================\n",
    "# Text Cleaning (LESS aggressive)\n",
    "# ===============================\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|<.*?>\", \" \", str(text).lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmas = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
    "        for word, pos in pos_tags\n",
    "    ]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "df['clean_comment'] = df['Comment'].apply(clean_text)\n",
    "\n",
    "# ===============================\n",
    "# TF-IDF Vectorization (STRONG)\n",
    "# ===============================\n",
    "vectorizer = TfidfVectorizer(\n",
    "     ngram_range=(1, 2),\n",
    "     max_features=50000,\n",
    "     min_df=3,\n",
    "     max_df=0.9,\n",
    "     sublinear_tf=True\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['clean_comment'])\n",
    "y = df['Insult']\n",
    "\n",
    "# ===============================\n",
    "# Train-Test Split\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Models (TEXT-OPTIMIZED)\n",
    "# ===============================\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "svm = LinearSVC(\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# ===============================\n",
    "# Train & Evaluate\n",
    "# ===============================\n",
    "models = {\n",
    "    \"Logistic Regression\": lr,\n",
    "    \"Linear SVM\": svm,\n",
    "    \"Naive Bayes\": nb\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n===============================\")\n",
    "    print(name)\n",
    "    print(\"===============================\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        print(\"ROC-AUC:\", roc_auc_score(y_test, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39491308-2c87-4525-8059-ea33e4316c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
